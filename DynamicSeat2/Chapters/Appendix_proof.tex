% !TEX root = sum1.tex
\clearpage
\section*{Proof}

\begin{pf}[Proof of Lemma \ref{lem_pattern}]
% To obtain a largest patterm, we need assign as less groups as possible.  
We can employ a greedy approach to generate a pattern by following these steps. First, we select the maximum group size, denoted as $n_M$, as many times as possible, filling up the available space. The remaining seats are then allocated to the group with the corresponding size. Let $L = n_M \cdot q + r$, where $q$ represents the number of times $n_M$ is selected (the quotient), and $r$ represents the remainder, indicating the number of remaining seats. It holds that $0 \leq r < n_M$. The loss of the pattern is $q \delta -\delta + \mathbb{1}(r)$. We can prove that it is the smallest loss by contradiction. 
Suppose the loss is not the smallest, there exists one pattern with a loss of $p < q \delta -\delta + \mathbb{1}(r)$. Then the largest number of seats occupied in this pattern is $\lfloor \frac{p}{\delta} \rfloor \cdot n_M$, which is always less than $L$ due to the inequality $\frac{\mathbb{1}}{\delta} \cdot n_M < r + n_M$. Consequently, the loss of $p$ cannot exist as it would contradict the maximum number of seats taken.
\qed
\end{pf}


% By employing this greedy approach, we can generate patterns that minimize the loss while maximizing seat utilization, ensuring efficient seat planning configurations that adhere to social distancing guidelines.

\begin{pf}[Proof of Lemma \ref{feasible_region}]
  Notice that $\mathbf{f}^{\intercal} = [-\mathbf{1},~\mathbf{0}], V =[W,~I]$, $W$ is a totally unimodular matrix. Then, we have $\bm{\alpha}^{\intercal}W \geq -\mathbf{1}, \bm{\alpha}^{\intercal} I \geq \mathbf{0}$. Thus, the feasible region is bounded. 
  Furthermore, let $\alpha_0 = 0$, then we have $0 \leq \alpha_i \leq \alpha_{i-1} +1$, $i \in \mathcal{M}$, so the extreme points are all integral.
  \qed
\end{pf}

\begin{pf}[Proof of Theorem \ref{optimal_sol_sub_dual}]
  According to the complementary slackness property, we can obtain the following equations
  \begin{align*}
    & \alpha_{i} (d_{i0} - d_{i \omega} - y_{i \omega}^{+} + y_{i+1, \omega}^{+} + y_{i \omega}^{-}) = 0, i =1,\ldots, M-1 \\
    & \alpha_{i} (d_{i0} - d_{i \omega} - y_{i \omega}^{+}+ y_{i \omega}^{-}) = 0, i = M \\
    & y_{i \omega}^{+}(\alpha_{i} - \alpha_{i-1}-1) = 0, i =1,\ldots, M \\
    & y_{i \omega}^{-} \alpha_{i} = 0, i =1,\ldots, M.
  \end{align*}
  
  When $y_{i \omega}^{-} >0$, we have $\alpha_{i} =0$; when $y_{i \omega}^{+} >0$, we have $\alpha_{i} = \alpha_{i-1} +1$.
  Let $\Delta d = d_{\omega} - d_0$, then the elements of $\Delta d$ will be a negative integer, positive integer and zero.
  When $y_{i \omega}^{+} = y_{i \omega}^{-} = 0$, if $i = M$, $\Delta d_{M} =0$, the value of objective function associated with $\alpha_{M}$ is always $0$, thus we have $0 \leq \alpha_{M} \leq \alpha_{M-1}+1$; if $i < M$, we have $y_{i+1, \omega}^{+} = \Delta d_{i} \geq 0$. If $y_{i+1, \omega}^{+} > 0$, the objective function associated with $\alpha_i$ is $\alpha_{i} \Delta d_{i} = \alpha_{i} y_{i+1, \omega}^{+}$, thus to minimize the objective value, we have $\alpha_i =0$; if $y_{i+1, \omega}^{+} = 0$, we have $0 \leq \alpha_{i} \leq \alpha_{i-1} +1$.
  \qed
  \end{pf}

  \begin{pf}[Proof of lemma \ref{one_ep_feasible}]
    Suppose we have one extreme point $\bm{\alpha}_{\omega}^{0}$ for each scenario. Then we have the following problem.
    \begin{equation}\label{lemma_eq}
      \begin{aligned}
        \max \quad & \mathbf{c}^{\intercal} \mathbf{x} + \sum_{\omega \in \Omega} p_{\omega} z_{\omega} \\
        \text {s.t.} \quad & \mathbf{n} \mathbf{x} \leq \mathbf{L} \\
        & (\bm{\alpha}_{\omega}^{0})^{\intercal}\mathbf{d}_{\omega} \geq (\bm{\alpha}_{\omega}^{0})^{\intercal} \mathbf{x} \mathbf{1} + z_{\omega}, \forall \omega \\
         & \mathbf{x} \in \mathbb{Z}_{+}
      \end{aligned}
    \end{equation}
    Problem \eqref{lemma_eq} reaches its maximum when $(\bm{\alpha}_{\omega}^{0})^{\intercal}\mathbf{d}_{\omega} = (\bm{\alpha}_{\omega}^{0})^{\intercal} \mathbf{x} \mathbf{1} + z_{\omega}, \forall \omega$. Substitute $z_{\omega}$ with these equations, we have 
    \begin{equation}\label{lemma_eq2}
      \begin{aligned}
        \max \quad & \mathbf{c}^{\intercal} \mathbf{x} - \sum_{\omega}p_{\omega}(\bm{\alpha}_{\omega}^{0})^{\intercal} \mathbf{x} \mathbf{1} + \sum_{\omega} p_{\omega} (\bm{\alpha}_{\omega}^{0})^{\intercal} \mathbf{d}_{\omega} \\
        \text {s.t.} \quad & \mathbf{n} \mathbf{x} \leq \mathbf{L} \\
        & \mathbf{x} \in \mathbb{Z}_{+}
      \end{aligned}
    \end{equation}
    Notice that $\mathbf{x}$ is bounded by $\mathbf{L}$, then the problem \eqref{lemma_eq} is bounded. Adding more optimality cuts will not make the optimal value larger. Thus, RBMP is bounded. 
    \qed
  \end{pf}

\begin{pf}[Proof of Lemma \ref{sol_relax_deter}]
  Treat the groups as the items, the rows as the knapsacks. There are $M$ types of items, the total number of which is $K = \sum_{i} d_i$, each item $k$ has a profit $p_k$ and weight $w_k$. 
  
  Then this Integer Programming is a special case of the Multiple Knapsack Problem(MKP). Consider the solution to the linear relaxation of \eqref{deter_upper}. Sort these items according to profit-to-weight ratios $\frac{p_1}{w_1} \geq \frac{p_2}{w_2} \geq \ldots \geq \frac{p_K}{w_K}$. 
  % $\delta$ is no less than 1, different types have
  Let the break item $b$ be given by $b=\min \{j: \sum_{k=1}^j w_k \geq L\}$, where $L = \sum_{j=1}^{N} L_j$ is the total size of all knapsacks. Then the Dantzig upper bound \cite{dantzig1957discrete} becomes $u_{\mathrm{MKP}}=\sum_{j=1}^{b-1} p_j+\left(L-\sum_{j=1}^{b-1} w_j\right) \frac{p_b}{w_b}$. The corresponding optimal solution is to accept the whole items from $1$ to $b-1$ and fractional $(L-\sum_{j=1}^{b-1} w_j)$ item $b$. Suppose the item $b$ belong to type $h$, then for $i < h$, $x_{ij}^{*} = 0$; for $i > h$, $x_{ij}^{*} = d_{i}$; for $i = h$, $\sum_{j} x_{ij}^{*} = (L - \sum_{i = h+1}^{M} {d_i n_i})/ n_h$. \qed
\end{pf}

\begin{pf}[Proof of Lemma \ref{bid-price}]
  According to the Lemma \ref{sol_relax_deter}, the aggregate optimal solution to relaxation of problem \eqref{deter_upper} takes the form $x e_{h} + \sum_{i=h+1} ^{M} d_{i} e_{i}$, then according to the complementary slackness property, we know that $z_1, \ldots, z_h = 0$. This implies that $\beta_j \geq \frac{n_i - \delta}{n_i}$ for $i = 1,\ldots, h$. Since $\frac{n_i - \delta}{n_i}$ increases with $i$, we have $\beta_j \geq \frac{n_h - \delta}{n_h}$. Consequently, we obtain $z_{i} \geq n_i - \delta - n_i \frac{n_h - \delta}{n_h} = \frac{\delta(n_i-n_h)}{n_h}$ for $i = h+1, \ldots, M$.
  
  Given that $\mathbf{d}$ and $\mathbf{L}$ are both no less than zero, the minimum value will be attained when $\beta_j = \frac{n_h - \delta}{n_h}$ for all $j$, and $z_i = \frac{\delta(n_i-n_h)}{n_h}$ for $i = h+1, \ldots, M$.  \qed
  \end{pf}

% Problem \ref{bid-price_dual} can also be obtained by the following approximation:

% $V_{t}(\mathbf{L}) - V_{t+1}(\mathbf{L}) = \mathbb{E}_{i \sim p}\left[\max_{\substack{j \in \mathcal{N}: \\ L_j \geqslant {n}_{i}}}\left\{V_{t+1}\left(\mathbf{L}- n_{i}\mathbf{e}_j^{\intercal} \right)- V_{t+1}(\mathbf{L}) + i, 0 \right\}\right]$

% Approximation: $V_{t}(\mathbf{L}) = \theta^{t} + \sum_{j=1}^{N} L_j \beta_j$, substitute it to the above DP, we have 

% $V_{t}(\mathbf{L}) - V_{t+1}(\mathbf{L}) = \mathbb{E}_{i \sim p}\left[\max_{\substack{j \in \mathcal{N}: \\ L_j \geqslant {n}_{i}}}\left\{-n_i \beta_j + i, 0 \right\}\right] = \sum_i p_i \max_{j} \{-n_i \beta_j + i, 0\}$.

% Let $z_i = \max_{j} \{-n_i \beta_j + i, 0\}$, the constraints of dual form can be developed.

% The objective funtion: $V_{1} = \sum_{t=1}^{T} (V_{t} - V_{t+1}) = \sum_{i} d_{i} z_{i} + \sum_{j}^{N} L_{j} \beta_j$.

\newpage
